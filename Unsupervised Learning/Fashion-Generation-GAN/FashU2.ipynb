{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:43:09.164754Z",
     "iopub.status.busy": "2021-10-16T03:43:09.164132Z",
     "iopub.status.idle": "2021-10-16T03:43:11.476318Z",
     "shell.execute_reply": "2021-10-16T03:43:11.475461Z",
     "shell.execute_reply.started": "2021-10-16T03:43:09.164643Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  #neural network\n",
    "import torchvision #image transformation\n",
    "import os\n",
    "import PIL #for image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid  #make grid of images\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Checkpoints from Input to output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:43:18.544410Z",
     "iopub.status.busy": "2021-10-16T03:43:18.543739Z",
     "iopub.status.idle": "2021-10-16T03:43:18.549580Z",
     "shell.execute_reply": "2021-10-16T03:43:18.548380Z",
     "shell.execute_reply.started": "2021-10-16T03:43:18.544371Z"
    }
   },
   "outputs": [],
   "source": [
    "if(os.path.isfile(\"../input/checkpointsanime/G-Checkpoint.pkl\") and os.path.isfile(\"../input/checkpointsanime/D-Checkpoint.pkl\")):\n",
    "    !cp -r '../input/checkpointsanime/' ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Parameters and Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:43:43.270757Z",
     "iopub.status.busy": "2021-10-16T03:43:43.270503Z",
     "iopub.status.idle": "2021-10-16T03:43:43.810008Z",
     "shell.execute_reply": "2021-10-16T03:43:43.809269Z",
     "shell.execute_reply.started": "2021-10-16T03:43:43.270728Z"
    }
   },
   "outputs": [],
   "source": [
    "datapath = '../input/fashion-product-images-dataset/'\n",
    "checkpt_path = './checkpointsanime/'\n",
    "epochs = 10000\n",
    "batch_size = 128\n",
    "image_size = 64 #resize image to this\n",
    "lr = 1e-4\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else 'cpu')\n",
    "last_epoch = 0\n",
    "nc = 3 #number of channels (RGB)\n",
    "nz = 200 #size of latent vector (input to first layer of Generator)\n",
    "ngf = ndf = image_size #size of feature maps for generator and discriminator\n",
    "ngpu = 1 #number of GPUs\n",
    "beta1 = 0.5 #parameter for Adam optimizer\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:43:22.691409Z",
     "iopub.status.busy": "2021-10-16T03:43:22.691133Z",
     "iopub.status.idle": "2021-10-16T03:43:23.658512Z",
     "shell.execute_reply": "2021-10-16T03:43:23.657742Z",
     "shell.execute_reply.started": "2021-10-16T03:43:22.691379Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.login(key='xxxxxxxxxxxxxxxxxxxxxx')   #enter your key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:43:46.500603Z",
     "iopub.status.busy": "2021-10-16T03:43:46.499904Z",
     "iopub.status.idle": "2021-10-16T03:43:59.664954Z",
     "shell.execute_reply": "2021-10-16T03:43:59.664168Z",
     "shell.execute_reply.started": "2021-10-16T03:43:46.500565Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "exp_name = wandb.util.generate_id()\n",
    "myrun = wandb.init(\n",
    "        project='FashU2',\n",
    "        group=exp_name,\n",
    "        config={\n",
    "            'Image Size':image_size,\n",
    "            'Num Channels':nc,\n",
    "            'nz':nz,\n",
    "            'ngf':ngf,\n",
    "            'ndf':ndf,\n",
    "            'Learning Rate':lr,\n",
    "            'Beta1':beta1,\n",
    "            'Epoch': epochs,\n",
    "            'Batch_size':batch_size,\n",
    "            'Loss':\"BCELoss\",            \n",
    "            'Optimizer':'Adam',\n",
    "            'Last Epoch':last_epoch,\n",
    "        }\n",
    ")\n",
    "config = wandb.config\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset and Set Data Loader\n",
    "\n",
    "Dataset : https://www.kaggle.com/paramaggarwal/fashion-product-images-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:45:15.253815Z",
     "iopub.status.busy": "2021-10-16T03:45:15.253569Z",
     "iopub.status.idle": "2021-10-16T03:50:01.424084Z",
     "shell.execute_reply": "2021-10-16T03:50:01.423349Z",
     "shell.execute_reply.started": "2021-10-16T03:45:15.253785Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=datapath,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Some Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:51:49.605825Z",
     "iopub.status.busy": "2021-10-16T03:51:49.605480Z",
     "iopub.status.idle": "2021-10-16T03:52:01.489653Z",
     "shell.execute_reply": "2021-10-16T03:52:01.488912Z",
     "shell.execute_reply.started": "2021-10-16T03:51:49.605776Z"
    }
   },
   "outputs": [],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Sample Training Images')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(make_grid(real_batch[0].to(device)[:64], normalize=True).cpu(),(1,2,0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:06.656323Z",
     "iopub.status.busy": "2021-10-16T03:52:06.655743Z",
     "iopub.status.idle": "2021-10-16T03:52:07.162913Z",
     "shell.execute_reply": "2021-10-16T03:52:07.162231Z",
     "shell.execute_reply.started": "2021-10-16T03:52:06.656282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generator Architecture\n",
    "# 200 -> 512\n",
    "# 512 -> 256\n",
    "# 256 -> 128\n",
    "# 128 -> 64\n",
    "# 64-> 3\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.gen = nn.Sequential(\n",
    "        #200->512\n",
    "        nn.ConvTranspose2d(nz, ngf*8, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(ngf*8),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        #512->256\n",
    "        nn.ConvTranspose2d(ngf*8, ngf*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ngf*4),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        #256->128\n",
    "        nn.ConvTranspose2d(ngf*4, ngf*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ngf*2),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        #128->64\n",
    "        nn.ConvTranspose2d(ngf*2, ngf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        #64->3\n",
    "        nn.ConvTranspose2d(ngf, nc, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):    #how model is going to run\n",
    "        return self.gen(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:20.091530Z",
     "iopub.status.busy": "2021-10-16T03:52:20.091267Z",
     "iopub.status.idle": "2021-10-16T03:52:20.688692Z",
     "shell.execute_reply": "2021-10-16T03:52:20.687905Z",
     "shell.execute_reply.started": "2021-10-16T03:52:20.091502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Discriminator Architecture\n",
    "#3 -> 32\n",
    "#32 -> 64\n",
    "#64 -> 128\n",
    "#128 -> 256\n",
    "#256 -> 512\n",
    "#512 -> 1\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.disc = nn.Sequential(\n",
    "        #3 -> 32\n",
    "        nn.Conv2d(nc, ndf//2, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ndf//2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "        #32 -> 64\n",
    "        nn.Conv2d(ndf//2, ndf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ndf),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        #64 -> 128\n",
    "        nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ndf*2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "        #128 -> 256\n",
    "        nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ndf*4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "        #256 -> 512\n",
    "        nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(ndf*8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "        #512 -> 1\n",
    "        nn.Conv2d(ndf*8, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.disc(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "## Generator Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:13.279718Z",
     "iopub.status.busy": "2021-10-16T03:52:13.279469Z",
     "iopub.status.idle": "2021-10-16T03:52:13.839283Z",
     "shell.execute_reply": "2021-10-16T03:52:13.838426Z",
     "shell.execute_reply.started": "2021-10-16T03:52:13.279688Z"
    }
   },
   "outputs": [],
   "source": [
    "netG = Generator(ngpu).to(device) #create generator instance on device(GPU else CPU)\n",
    "netG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:24.016041Z",
     "iopub.status.busy": "2021-10-16T03:52:24.015379Z",
     "iopub.status.idle": "2021-10-16T03:52:24.594512Z",
     "shell.execute_reply": "2021-10-16T03:52:24.593151Z",
     "shell.execute_reply.started": "2021-10-16T03:52:24.016005Z"
    }
   },
   "outputs": [],
   "source": [
    "netD = Discriminator(ngpu).to(device) #create generator instance on device(GPU else CPU)\n",
    "netD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Wandb to watch Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:27.380353Z",
     "iopub.status.busy": "2021-10-16T03:52:27.380103Z",
     "iopub.status.idle": "2021-10-16T03:52:27.886438Z",
     "shell.execute_reply": "2021-10-16T03:52:27.885690Z",
     "shell.execute_reply.started": "2021-10-16T03:52:27.380324Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.watch(netD, log_freq=100)\n",
    "wandb.watch(netG, log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:30.114637Z",
     "iopub.status.busy": "2021-10-16T03:52:30.114373Z",
     "iopub.status.idle": "2021-10-16T03:52:30.778740Z",
     "shell.execute_reply": "2021-10-16T03:52:30.778025Z",
     "shell.execute_reply.started": "2021-10-16T03:52:30.114605Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(image_size, nz, 1, 1, device = device) #to visualize generator progress with same set of image\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:31.835845Z",
     "iopub.status.busy": "2021-10-16T03:52:31.835559Z",
     "iopub.status.idle": "2021-10-16T03:52:32.353064Z",
     "shell.execute_reply": "2021-10-16T03:52:32.352353Z",
     "shell.execute_reply.started": "2021-10-16T03:52:31.835803Z"
    }
   },
   "outputs": [],
   "source": [
    "optim_g = optim.Adam(netG.parameters(), lr = lr)\n",
    "optim_d = optim.Adam(netD.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:34.797695Z",
     "iopub.status.busy": "2021-10-16T03:52:34.797022Z",
     "iopub.status.idle": "2021-10-16T03:52:35.324127Z",
     "shell.execute_reply": "2021-10-16T03:52:35.323384Z",
     "shell.execute_reply.started": "2021-10-16T03:52:34.797658Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_chckpt():\n",
    "    torch.save({\n",
    "        'epoch':epoch,\n",
    "        'model_state_dict':netG.state_dict(),\n",
    "        'optimizer_state_dict':optim_g.state_dict()\n",
    "    }, f\"{checkpt_path}G-Checkpoint.pkl\")\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch':epoch,\n",
    "        'model_state_dict':netD.state_dict(),\n",
    "        'optimizer_state_dict':optim_d.state_dict()\n",
    "    }, f\"{checkpt_path}D-Checkpoint.pkl\")\n",
    "    \n",
    "    print(f\"Saved Checkpoint:\\n\\t Epoch : {epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:36.571701Z",
     "iopub.status.busy": "2021-10-16T03:52:36.571463Z",
     "iopub.status.idle": "2021-10-16T03:52:37.156408Z",
     "shell.execute_reply": "2021-10-16T03:52:37.155657Z",
     "shell.execute_reply.started": "2021-10-16T03:52:36.571673Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_chckpt():\n",
    "    checkpoint = torch.load(f\"{checkpt_path}G-Checkpoint.pkl\")\n",
    "    netG.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optim_g.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    checkpoint = torch.load(f\"{checkpt_path}D-Checkpoint.pkl\")\n",
    "    netD.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optim_d.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "\n",
    "    print(f\"Checkpoint Loaded:\\n\\t Epoch : {last_epoch}\")\n",
    "    return last_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from Previous Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:38.106734Z",
     "iopub.status.busy": "2021-10-16T03:52:38.106493Z",
     "iopub.status.idle": "2021-10-16T03:52:38.618484Z",
     "shell.execute_reply": "2021-10-16T03:52:38.617828Z",
     "shell.execute_reply.started": "2021-10-16T03:52:38.106705Z"
    }
   },
   "outputs": [],
   "source": [
    "if(os.path.isfile(f\"{checkpt_path}G-Checkpoint.pkl\") and os.path.isfile(f\"{checkpt_path}D-Checkpoint.pkl\")):\n",
    "    last_epoch = load_chckpt()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Fake Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:39.875262Z",
     "iopub.status.busy": "2021-10-16T03:52:39.874718Z",
     "iopub.status.idle": "2021-10-16T03:52:40.441905Z",
     "shell.execute_reply": "2021-10-16T03:52:40.441153Z",
     "shell.execute_reply.started": "2021-10-16T03:52:39.875222Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_fake(noise):   #log fake images\n",
    "    fake_img = netG(noise) #generate image from noise\n",
    "    fake_img = fake_img.detach().cpu() #deteach since only used for visualization\n",
    "    grid = make_grid(fake_img[:64], nrow=8).permute(1, 2, 0)\n",
    "    wandb.log({'Generated Image' : wandb.Image(grid.numpy().clip(0, 1))})\n",
    "    #plt.figure(figsize=(10, 10))\n",
    "    #plt.imshow(grid.clip(0, 1));\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T03:52:42.848331Z",
     "iopub.status.busy": "2021-10-16T03:52:42.847782Z",
     "iopub.status.idle": "2021-10-16T03:57:22.183897Z",
     "shell.execute_reply": "2021-10-16T03:57:22.180761Z",
     "shell.execute_reply.started": "2021-10-16T03:52:42.848292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "for epoch in range(last_epoch, epochs):\n",
    "    for i, data in enumerate(dataloader, 0):    #i - index, data - value\n",
    "        \n",
    "        #Discriminator - real image batch\n",
    "        netD.zero_grad()  #set gradients to zero\n",
    "        \n",
    "        real = data[0].to(device)  #bind with device\n",
    "        batch_s = real.size(0)  #find batch size (since in last iteration batch size may vary)\n",
    "        label = torch.full((batch_s,), real_label, dtype=torch.float, device=device)   #create tensor with real_label with current batch size\n",
    "        output = netD(real).view(-1)  #reshaping output from discriminator to 1D (since only a float number is needed)\n",
    "        errD_real = loss_fn(output, label) #calc loss of discriminator for real images batch\n",
    "        errD_real.backward()   #calculating gradient\n",
    "        D_x = output.mean().item()  #mean loss for current batch of real images\n",
    "        \n",
    "        #Discriminator - fake image batch\n",
    "        noise = torch.randn(batch_s, nz, 1, 1, device = device) #generate noise\n",
    "        fake = netG(noise)  #fake image from noise\n",
    "        #not needed to find batch size since this is fake can generate batch_size number of images each time\n",
    "        #label = fill_(fake_label)  #generate fake labels of batch_size\n",
    "        #label = torch.full((batch_s,), fake_label, dtype=torch.float, device=device)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)  #detach since gradient should not be altered by discriminator(only to find probability)\n",
    "        errD_fake = loss_fn(output, label)  #calc loss of discriminator for fake images batch\n",
    "        errD_fake.backward()   #calculating gradient\n",
    "        D_G_z1 = output.mean().item()  #mean loss for current batch of fake images\n",
    "        \n",
    "        #calculate accumulated loss of discriminator\n",
    "        errD = errD_real + errD_fake\n",
    "        #update D\n",
    "        optim_d.step()\n",
    "        \n",
    "        #Generator\n",
    "        netG.zero_grad()  #set gradients to zero\n",
    "        #should use same noise\n",
    "        label.fill_(real_label)  #generate real labels of batch_size\n",
    "        output = netD(fake).view(-1)  #reshaping output from discriminator to 1D (since only a float number is needed)\n",
    "        errG = loss_fn(output, label)  #calc generator loss\n",
    "        errG.backward()  #calculating gradient\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optim_g.step()\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # log in every 200 batches in each epoch\n",
    "        if (iters % 200 == 0) or ((epoch == epochs-1) and (i == len(dataloader)-1)):\n",
    "            #log wandb\n",
    "            wandb.log({'Epoch':epoch, 'Discriminator Loss':errD.item(), 'Generator Loss':errG.item()})\n",
    "            wandb.save(f\"{checkpt_path}G-Checkpoint.pkl\")\n",
    "            wandb.save(f\"{checkpt_path}D-Checkpoint.pkl\")\n",
    "            print(\"Checkpoint Logged\")\n",
    "                \n",
    "            #accumulate different stages of same noise for animation\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "                grid = make_grid(fake[:25], nrow=5).permute(1, 2, 0)\n",
    "            img_list.append(make_grid(fake, padding=2, normalize=True))\n",
    "            \n",
    "            #wandb log generated images of different noise\n",
    "            log_fake(torch.randn(batch_size, nz, 1, 1, device = device))\n",
    "            \n",
    "        iters += 1\n",
    "    save_chckpt()\n",
    "    \n",
    "    # save animation every 5 epochs\n",
    "    if(epoch % 5 ==0):\n",
    "        fig = plt.figure(figsize=(64,64))\n",
    "        plt.axis(\"off\")\n",
    "        ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "        ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "        writervideo = animation.FFMpegWriter(fps=2)\n",
    "        ani.save('Animation.mp4', writer=writervideo)\n",
    "        wandb.save('./Animation.mp4')\n",
    "        #HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
