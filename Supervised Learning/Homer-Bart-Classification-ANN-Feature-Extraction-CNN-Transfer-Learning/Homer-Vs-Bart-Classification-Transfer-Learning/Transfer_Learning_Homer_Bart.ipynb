{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_Cats_Dogs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaSeXlJWHsnS"
      },
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
        "#from keras.utils import plot_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from keras.models import save_model\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziiLAMYrH54D"
      },
      "source": [
        "#load dataset\n",
        "zip_obj = zipfile.ZipFile(file = '/content/drive/MyDrive/Computer Vision Masterclass/Datasets/homer_bart_2.zip', mode = 'r')    #create ZipFile object in read mode\n",
        "zip_obj.extractall('./')    #extract in current location\n",
        "zip_obj.close() #close to release memory\n",
        "#tf.keras.preprocessing.image.load_img('homer_bart_2/training_set/homer/homer100.bmp')\n",
        "#tf.keras.preprocessing.image.load_img('homer_bart_2/training_set/bart/bart100.bmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ_b7Pw6IMjc"
      },
      "source": [
        "#train test split\n",
        "#data augmentation\n",
        "train_generator = ImageDataGenerator(rescale = 1./255,  #generate train images\n",
        "                                     rotation_range=7,\n",
        "                                     horizontal_flip=True,\n",
        "                                     zoom_range=0.2)\n",
        "\n",
        "train_dataset = train_generator.flow_from_directory('homer_bart_2/training_set',\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size = 8,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nt6iic5ISdc"
      },
      "source": [
        "test_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_dataset = test_generator.flow_from_directory('homer_bart_2/test_set', \n",
        "                                                  target_size=(256,256),\n",
        "                                                  batch_size=1,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4tWUN7CIXUj"
      },
      "source": [
        "print(train_dataset.classes, train_dataset.class_indices,sep='\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNcE6aIZND"
      },
      "source": [
        "#transfer learning\n",
        "base_model = tf.keras.applications.ResNet50(weights='imagenet',\n",
        "                                            include_top=False,\n",
        "                                            input_tensor=Input(shape=(256, 256,3)))\n",
        "#train using imagenet dataset\n",
        "#include_top = False - only bottom layers ae included\n",
        "#input_tensor - shape of input the model should get (since we should send our image\n",
        "#dataset we should specify the sizes (many sizes are available ...refer documentation))\n",
        "base_model.trainable=False\n",
        "#since we need to use weights and so not needed to train again"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZeXze8EIbR6"
      },
      "source": [
        "#visualise model\n",
        "base_model.summary()\n",
        "#plot_model(base_model,'ResNet50_Model.jpg', show_shapes=True)\n",
        "print(\"Number of layers in base_model :\",len(base_model.layers))\n",
        "print(base_model.output)    #return last layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNi2kA5FIdYj"
      },
      "source": [
        "#Custom dense layers\n",
        "#(2048+2)/2 = 1025 hidden layer neurons\n",
        "head_model = base_model.output      #joins last layer of base model with head model\n",
        "head_model = GlobalAveragePooling2D()(head_model)       #other way to flatten and connect with head_model\n",
        "head_model = Dense(1025, activation='relu')(head_model) \n",
        "head_model = Dropout(0.2)(head_model)\n",
        "head_model = Dense(1025, activation='relu')(head_model)\n",
        "head_model = Dropout(0.2)(head_model)\n",
        "head_model = Dense(2, activation='softmax')(head_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3GaP490Idnr"
      },
      "source": [
        "#combine base_model with head_model\n",
        "model = Model(inputs = base_model.input, outputs = head_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNiVxuYTIojF"
      },
      "source": [
        "#visualise entire model\n",
        "model.summary()\n",
        "#plot_model(model,'Entire_Model.jpg', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fus0iIbcIr8z"
      },
      "source": [
        "#compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eZ6PEdFIt6D"
      },
      "source": [
        "#train\n",
        "model_history = model.fit(train_dataset, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipr4k680Ivfs"
      },
      "source": [
        "#evaluate\n",
        "predictions = model.predict(test_dataset)\n",
        "predictions = np.argmax(predictions, axis =1)\n",
        "print(\"Accuracy :\",accuracy_score(predictions, test_dataset.classes)*100)\n",
        "#even transfer learning gives lesser accuracy than our own custom CNN\n",
        "#because might be due to that imagenet dataset is real world while \n",
        "#this dataset is animated\n",
        "cm = confusion_matrix(predictions, test_dataset.classes)\n",
        "sns.heatmap(cm, annot=True)\n",
        "print(classification_report(predictions, test_dataset.classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9ALexjCJhYk"
      },
      "source": [
        "#fine tuning\n",
        "for layer in base_model.layers:\n",
        "    print(layer, layer.trainable)   #view trainability of all layers\n",
        "    \n",
        "print(len(base_model.layers))   #find how many layers totally (175)\n",
        "\n",
        "for layer in base_model.layers[140:]:\n",
        "    layer.trainable = True          #setting layers after 140 to be trainable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdyHbe9rJ_Yz"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    print(layer, layer.trainable)   #view trainability of all layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_AAZz5ZJlo7"
      },
      "source": [
        "#compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M7XM_2UJmzL"
      },
      "source": [
        "#train\n",
        "model_history = model.fit(train_dataset, epochs = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukUF7P95KGYV"
      },
      "source": [
        "#evaluation on test set\n",
        "predictions = model.predict(test_dataset)\n",
        "#since we used categorical model(not binary) we get probabilities for an image to be in each class\n",
        "#so we consider that the image belogs to the class with higher probability\n",
        "#print(predictions)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "#print(test_dataset.classes) #expected classes\n",
        "#print('\\n',predictions) #predicted classes\n",
        "print(\"Accuracy :\",accuracy_score(predictions, test_dataset.classes)*100)\n",
        "cm = confusion_matrix(predictions, test_dataset.classes)\n",
        "sns.heatmap(cm, annot=True)\n",
        "print(classification_report(predictions, test_dataset.classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYSafOC3KUrr"
      },
      "source": [
        "#save model\n",
        "model_json = model.to_json()\n",
        "with open('model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model_saved = save_model(model, './weights.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Wqbo4uK7oc"
      },
      "source": [
        "#load model\n",
        "with open('model.json', 'r') as json_file:\n",
        "    json_saved_model = json_file.read()\n",
        "\n",
        "model_loaded = tf.keras.models.model_from_json(json_saved_model)\n",
        "model_loaded.load_weights('weights.hdf5')\n",
        "model_loaded.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_loaded.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3torOFqK9JE"
      },
      "source": [
        "#test single image\n",
        "path = 'homer_bart_2/test_set/homer/homer16.bmp'\n",
        "image = cv2.imread(path)\n",
        "image = cv2.resize(image, (256,256))\n",
        "image = image/ 255    #normalise\n",
        "#print(image.shape)\n",
        "image = image.reshape(-1, 256,256,3)      #reshape in format to send more than one image to predict\n",
        "#print(image.shape)\n",
        "\n",
        "result = model_loaded(image)\n",
        "#print(result)  #probabilities that the image belong to each class\n",
        "result = np.argmax(result, axis=1)\n",
        "\n",
        "if(result==0):\n",
        "    print('Bart')\n",
        "else:\n",
        "    print('Homer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54tszcNJLb1e"
      },
      "source": [
        "tf.keras.preprocessing.image.load_img(path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}