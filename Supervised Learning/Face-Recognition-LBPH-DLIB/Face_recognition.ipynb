{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgQKD4_BSOPP"
   },
   "source": [
    "## OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8zOtNhKLp-Z"
   },
   "source": [
    "### Loading the dataset\n",
    "\n",
    "- Yale faces database: http://vision.ucsd.edu/content/yale-face-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ta2EHPg1-0Gn",
    "outputId": "53ef09d3-b0f7-4e5c-ee86-0005d56c1c65"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fM29c2T7_e5V"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = '/content/drive/MyDrive/Computer Vision Masterclass/Datasets/yalefaces.zip'\n",
    "zip_object = zipfile.ZipFile(file=path, mode = 'r')\n",
    "zip_object.extractall('./')\n",
    "zip_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k3yuCEM06FJ"
   },
   "source": [
    "### Pre-processing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TKNpS9sB-rU",
    "outputId": "052d6a43-e999-42b7-bcc7-8a9dce66f8b1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('/content/yalefaces/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_6MUlv2Cfvg"
   },
   "outputs": [],
   "source": [
    "def get_image_data():\n",
    "  paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]\n",
    "  #print(paths)\n",
    "  faces = []\n",
    "  ids = []\n",
    "  for path in paths:\n",
    "    #print(path)\n",
    "    image = Image.open(path).convert('L')\n",
    "    #print(type(image))\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    #print(type(image_np))\n",
    "    id = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
    "    #print(id)\n",
    "    ids.append(id)\n",
    "    faces.append(image_np)\n",
    "\n",
    "  return np.array(ids), faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kjNb0PaC6-2"
   },
   "outputs": [],
   "source": [
    "ids, faces = get_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1SKHBy2GFzl",
    "outputId": "36f60462-7ff2-4956-9fcb-1e13084c7b7d"
   },
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRuJuHRLvcmW"
   },
   "source": [
    "### Training the LBPH classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTHLAAnTLBfY"
   },
   "outputs": [],
   "source": [
    "# threshold: 1.7976931348623157e+308\n",
    "# radius: 1\n",
    "# neighbors: 8\n",
    "# grid_x: 8\n",
    "# grid_y: 8\n",
    "\n",
    "lbph_classifier = cv2.face.LBPHFaceRecognizer_create(radius = 4, neighbors=14, grid_x = 9, grid_y = 9)\n",
    "lbph_classifier.train(faces, ids)\n",
    "lbph_classifier.write('lbph_classifier.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37itAmjd1AGm"
   },
   "source": [
    "### Recognizing faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQ3srgyaMeUs",
    "outputId": "1658170c-488c-4fc4-ee8b-a9275626c4ad"
   },
   "outputs": [],
   "source": [
    "lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph_face_classifier.read('/content/lbph_classifier.yml')\n",
    "test_image = '/content/yalefaces/test/subject10.sad.gif'\n",
    "image = Image.open(test_image).convert('L')\n",
    "image_np = np.array(image, 'uint8')\n",
    "image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ut_l-QSNNn7t",
    "outputId": "8311be6a-5673-4959-df70-502cea2bfe52"
   },
   "outputs": [],
   "source": [
    "prediction = lbph_face_classifier.predict(image_np)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "Fb9T5wF2N71g",
    "outputId": "0e888ff1-ff68-48f8-b457-29ef754bad9e"
   },
   "outputs": [],
   "source": [
    "expected_output = int(os.path.split(test_image)[1].split('.')[0].replace('subject', ''))\n",
    "cv2.putText(image_np, 'Pred: ' + str(prediction[0]), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "cv2.putText(image_np, 'Exp: ' + str(expected_output), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "cv2_imshow(image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eyUv8l00oAt"
   },
   "source": [
    "### Evaluating the face classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJcCdWm7P33p"
   },
   "outputs": [],
   "source": [
    "paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]\n",
    "predictions = []\n",
    "expected_outputs = []\n",
    "for path in paths:\n",
    "  #print(path)\n",
    "  image = Image.open(path).convert('L')\n",
    "  image_np = np.array(image, 'uint8')\n",
    "  prediction, _ = lbph_face_classifier.predict(image_np)\n",
    "  expected_output = int(os.path.split(path)[1].split('.')[0].replace('subject', '')) \n",
    "\n",
    "  predictions.append(prediction)\n",
    "  expected_outputs.append(expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOT1AMkhRBmV"
   },
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "expected_outputs = np.array(expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVQgB2ScRLmx",
    "outputId": "243ca806-68ab-4061-a7b7-34a1dff1ee26"
   },
   "outputs": [],
   "source": [
    "predictions, expected_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "brDGncBPRjKf",
    "outputId": "bf15f62e-5497-4722-8e1f-237b3e6e11b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn\n",
    "accuracy_score(expected_outputs, predictions)\n",
    "cm = confusion_matrix(expected_outputs, predictions)\n",
    "seaborn.heatmap(cm, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw1aTLB6SdP2"
   },
   "source": [
    "## Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7svnaxog97Ss"
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO_I5o6RKpFt"
   },
   "source": [
    "### Detecting facial points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYyZCTG8-Kxz"
   },
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n",
    "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Computer Vision Masterclass/Weights/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "XlywU7Y7_bsi",
    "outputId": "6a443216-a5d4-40a6-d133-01bb7afef3f9"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/drive/MyDrive/Computer Vision Masterclass/Images/people2.jpg')\n",
    "face_detection = face_detector(image, 1)\n",
    "for face in face_detection:\n",
    "  points = points_detector(image, face)\n",
    "  for point in points.parts():\n",
    "    cv2.circle(image, (point.x, point.y), 2, (0,255,0), 1)\n",
    "\n",
    "  #print(points.parts())\n",
    "  #print(len(points.parts()))\n",
    "\n",
    "  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "  cv2.rectangle(image, (l, t), (r, b), (0,255,255), 2)\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhZ2dDNe54Oe"
   },
   "source": [
    "### Detecting facial descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBunTbwvEbBD"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJBYZDULEjN4"
   },
   "outputs": [],
   "source": [
    "# Resnet: https://arxiv.org/abs/1512.03385\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Computer Vision Masterclass/Weights/shape_predictor_68_face_landmarks.dat')\n",
    "face_descriptor_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/Computer Vision Masterclass/Weights/dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3DNqWwugGqQM",
    "outputId": "ca66840e-cea2-4a44-d6a1-c7e3030620b0"
   },
   "outputs": [],
   "source": [
    "index = {}\n",
    "idx = 0\n",
    "face_descriptors = None\n",
    "\n",
    "paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]\n",
    "for path in paths:\n",
    "  #print(path)\n",
    "  image = Image.open(path).convert('RGB')\n",
    "  image_np = np.array(image, 'uint8')\n",
    "  face_detection = face_detector(image_np, 1)\n",
    "  for face in face_detection:\n",
    "    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()\n",
    "    cv2.rectangle(image_np, (l, t), (r, b), (0, 0, 255), 2)\n",
    "\n",
    "    points = points_detector(image_np, face)\n",
    "    for point in points.parts():\n",
    "      cv2.circle(image_np, (point.x, point.y), 2, (0, 255, 0), 1)\n",
    "\n",
    "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "    #print(type(face_descriptor))\n",
    "    #print(len(face_descriptor))\n",
    "    #print(face_descriptor)\n",
    "    face_descriptor = [f for f in face_descriptor]\n",
    "    #print(face_descriptor)\n",
    "    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "    #print(face_descriptor)\n",
    "    #print(face_descriptor.shape)\n",
    "    face_descriptor = face_descriptor[np.newaxis, :]\n",
    "    #print(face_descriptor.shape)\n",
    "    #print(face_descriptor)\n",
    "\n",
    "    if face_descriptors is None:\n",
    "      face_descriptors = face_descriptor\n",
    "    else:\n",
    "      face_descriptors = np.concatenate((face_descriptors, face_descriptor), axis = 0)\n",
    "\n",
    "    index[idx] = path\n",
    "    idx += 1\n",
    "  cv2_imshow(image_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_rUY0dO5-J0"
   },
   "source": [
    "### Detecting faces with Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E-034wqtVHVz",
    "outputId": "07793836-e026-4e5e-a55b-7eb4b4546e7d"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "predictions = []\n",
    "expected_outputs = []\n",
    "\n",
    "paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]\n",
    "for path in paths:\n",
    "  image = Image.open(path).convert('RGB')\n",
    "  image_np = np.array(image, 'uint8')\n",
    "  face_detection = face_detector(image_np, 1)\n",
    "  for face in face_detection:\n",
    "    points = points_detector(image_np, face)\n",
    "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np, points)\n",
    "    face_descriptor = [f for f in face_descriptor]\n",
    "    face_descriptor = np.asarray(face_descriptor, dtype=np.float64)\n",
    "    face_descriptor = face_descriptor[np.newaxis, :]\n",
    "\n",
    "    distances = np.linalg.norm(face_descriptor - face_descriptors, axis = 1)\n",
    "    min_index = np.argmin(distances)\n",
    "    min_distance = distances[min_index]\n",
    "    if min_distance <= threshold:\n",
    "      name_pred = int(os.path.split(index[min_index])[1].split('.')[0].replace('subject', ''))\n",
    "    else:\n",
    "      name_pred = 'Not identified'\n",
    "\n",
    "    name_real = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))\n",
    "\n",
    "    predictions.append(name_pred)\n",
    "    expected_outputs.append(name_real)\n",
    "\n",
    "    cv2.putText(image_np, 'Pred: ' + str(name_pred), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "    cv2.putText(image_np, 'Exp : ' + str(name_real), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "\n",
    "\n",
    "  cv2_imshow(image_np)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "expected_outputs = np.array(expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVdGI3xoatoE",
    "outputId": "f064c9d1-2e3e-4af1-a862-8b1a56e81d05"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(expected_outputs, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_7ri5zj6Alb"
   },
   "source": [
    "## jones_gabriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3k4LA3AZbWd3",
    "outputId": "d9924062-ae19-4e8b-d3d9-46c9c1aac979"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNtcCZURbUhD"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = '/content/drive/MyDrive/Computer Vision Masterclass/Datasets/jones_gabriel.zip'\n",
    "zip_object = zipfile.ZipFile(file=path, mode='r')\n",
    "zip_object.extractall('./')\n",
    "zip_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBLCIuBNbY0S"
   },
   "outputs": [],
   "source": [
    "def get_image_data():\n",
    "  paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]\n",
    "  faces = []\n",
    "  ids = []\n",
    "  for path in paths:\n",
    "    image = Image.open(path).convert('L')\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    id = int(path.split('.')[1])\n",
    "    \n",
    "    ids.append(id)\n",
    "    faces.append(image_np)\n",
    "  \n",
    "  return np.array(ids), faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgoUfIboba2L"
   },
   "outputs": [],
   "source": [
    "ids, faces = get_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nm7Rm6dnbc7A"
   },
   "outputs": [],
   "source": [
    "lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph_classifier.train(faces, ids)\n",
    "lbph_classifier.write('lbph_classifier.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sQvshSRbfBl"
   },
   "outputs": [],
   "source": [
    "lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph_face_classifier.read('/content/lbph_classifier.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJMfLHRHbhBD"
   },
   "outputs": [],
   "source": [
    "image = Image.open('/content/jones_gabriel/person.1.1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TgFA9zScblF3",
    "outputId": "2bc91209-5ef1-4952-e4d3-f23823f30058"
   },
   "outputs": [],
   "source": [
    "paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]\n",
    "for path in paths:\n",
    "  image = Image.open(path).convert('L')\n",
    "  image_np = np.array(image, 'uint8')\n",
    "  prediction, _ = lbph_face_classifier.predict(image_np)\n",
    "  expected_output = int(path.split('.')[1])\n",
    "\n",
    "  cv2.putText(image_np, 'Pred: ' + str(prediction), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "  cv2.putText(image_np, 'Exp: ' + str(expected_output), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))\n",
    "  cv2_imshow(image_np)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Face recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
